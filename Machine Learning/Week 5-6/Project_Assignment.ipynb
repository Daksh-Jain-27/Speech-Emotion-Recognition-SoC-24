{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "w98ePCRA82pj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(filename, list_of_features):\n",
        "        audio_data, sample_rate = librosa.load(filename)\n",
        "        features = []\n",
        "        if 'mfcc' in list_of_features:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13).T, axis=0)\n",
        "            features.extend(mfccs)\n",
        "        if 'chroma' in list_of_features:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(y=audio_data, sr=sample_rate).T, axis=0)\n",
        "            features.extend(chroma)\n",
        "        if 'melspectogram' in list_of_features:\n",
        "            melspec = np.mean(librosa.feature.melspectrogram(y=audio_data, sr=sample_rate).T, axis=0)\n",
        "            features.extend(melspec)\n",
        "        return features"
      ],
      "metadata": {
        "id": "1gg-XRx-9B4e"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(test_size=0.2):\n",
        "    data_dir = \"/content/drive/MyDrive/Audio_Speech_Actors_01-24\"\n",
        "    features = []\n",
        "    labels = []\n",
        "    list_of_features = ['mfcc', 'chroma', 'melspectogram']\n",
        "\n",
        "    for root, _, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                feature = extract_features(file_path, list_of_features)\n",
        "                if feature is not None:\n",
        "                    features.append(feature)\n",
        "                    labels.append(file.split('-')[2])\n",
        "\n",
        "\n",
        "    X = np.array(features)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y = to_categorical(le.fit_transform(y))\n",
        "\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=42)"
      ],
      "metadata": {
        "id": "dPWJOnTq9PqQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(300, activation='relu', input_shape=(input_shape,)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ThVaW-S_Tu6U"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val):\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        LearningRateScheduler(lambda epoch: 1e-3 * 10 ** (epoch / 20)),\n",
        "        ModelCheckpoint(\"best_model.keras\", monitor='val_loss', save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                        epochs=300, batch_size=256, callbacks=callbacks)\n",
        "    return history"
      ],
      "metadata": {
        "id": "r2F727P2WH1_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test_labels = np.argmax(y_test, axis=1)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    accuracy = np.sum(y_pred_labels == y_test_labels) / len(y_test_labels)\n",
        "    print(f\"Test Accuracy: {accuracy:.2%}\")\n",
        "    print(classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "id": "bnIXFEidbSTR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data(test_size=0.2)\n",
        "model = build_model(X_train.shape[1], y_train.shape[1])\n",
        "train_model(model, X_train, y_train, X_test, y_test)\n",
        "evaluate_model(model, X_test, y_test)"
      ],
      "metadata": {
        "id": "idW82uDng3n6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}